---
title: "Machine Learning 1"
author: "Kai Movellan"
date: "10/21/2021"
output:
  pdf_document: default
  html_document: default
---

First up is clustering methods

# K means clustering 

The function in base R to do Kmeans is called `kmeans()`

First make up some data where we know the answer should be:

```{r}
#rnorm makes a random set of data close to -3
tmp <- c(rnorm(30,-3), rnorm(30,3))
#tmp
#hist(tmp)
x<- cbind(x=tmp,y=rev(tmp))
#x
plot(x)
```

>Q. Can we use kmeans() to cluster this data setting k 2 and nstart 20?

```{r}
km<-kmeans(x,centers=2, nstart=20)
km
#clustering vector: says for all the data points which group it belongs to 
```

>Q. How many points are in each cluster?

```{r}
km$size
```

>Q. What 'component' of your result object details cluster assignment/ membership?

```{r}
km$cluster
```

>Q. What 'component' of your result object details cluster centers?

```{r}
km$centers
```

>Q. Plot x colored by the kmeans cluster assignment and cluster centers as blue points

```{r}
plot(x,col=km$cluster)
points(km$centers, col="blue", pch=20, cex=2)

```

# Hierarchical Clustering

analysis on a set of dissimilarities and methods for analyzing it.

Analuyze this dara with hclust()

Demonstrate the use of dist(), hclust(), plot(), and cutree() functions to do clustering
Generate aenarograms and return cluster assignment/ membership vector...

```{r}
hc<-hclust(dist(x))
hc
```

There is a plot method for hclust result objects. Let's see it

```{r}
plot(hc)
```

To get our cluster membership vector we have to do a wee bit more work.
We have to "cut" the tree with what we think makes sense. For this we use `cutree()` function

```{r}
cutree(hc,h=6)
```

You can also call `cutree()` setting k=the number of grps/clusters you want

```{r}
grps<-cutree(hc, k=2)
```

Make our result plot

```{r}
plot(x,col=grps)
```

#Principal Component Analysis (PCA)

## PCA of UK food data

Read data from website and try a few visualizations

>Q1. How many rows and columns are in your new data frame named x? What R functions could you use to answer this questions?

```{r}
# Complete the following code to find out how many rows and columns are in x?
url <- "https://tinyurl.com/UK-foods"
x <- read.csv(url)
```

```{r}
dim(x)
```

Pants! this should be 17x4

```{r}
# Note how the minus indexing works
rownames(x) <- x[,1]
x <- x[,-1]
head(x)
```

The dimmensions are 17x4

>Q2. Which approach to solving the ‘row-names problem’ mentioned above do you prefer and why? Is one approach more robust than another under certain circumstances?

```{r}
x <- read.csv(url, row.names=1)
dim(x)
```

The minus indexing removes a collumn every time the code is ran

>Q3: Changing what optional argument in the above barplot() function results in the following plot?

```{r}
cols<-rainbow(nrow(x))
barplot(as.matrix(x),col=cols,beside=TRUE)
```

>Q5: Generating all pairwise plots may help somewhat. Can you make sense of the following code and resulting figure? What does it mean if a given point lies on the diagonal for a given plot?

```{r}
#A plot of all possible pairs of countries 
pairs(x,col=cols,pch=16)
```

If a point lies on the diagonal the data is similar. When the points aren't on the diagonal line the data is different

>Q6. What is the main differences between N. Ireland and the other countries of the UK in terms of this data-set?



PCA to the rescue!!
The main base R PCA function is called `prcomp()`and we will need to give it the transpose of the input data!

```{r}
#t(x)
# Use the prcomp() PCA function 
pca<-prcomp(t(x)) 
summary(pca)
```

```{r}
attributes(pca)
pca$sdev
```

>Q7. Complete the code below to generate a plot of PC1 vs PC2. The second line adds text labels over the data points

To make our new PCA plot (PCA score plot) we access `pca$x`

```{r}
pca$x
```


```{r}
# Plot PC1 vs PC2
plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2", xlim=c(-270,500))
text(pca$x[,1], pca$x[,2], colnames(x))

```

> Q8. Customize your plot so that the colors of the country names match the colors in our UK and Ireland map and table at start of this document.

```{r}
country_cols <- c("orange","red","blue", "dark green")
plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2", xlim=c(-270,500),pch=1, cex=5,col=country_cols)
text(pca$x[,1], pca$x[,2], colnames(x), col=country_cols, cex=0.5)
```

```{r}
v <- round( pca$sdev^2/sum(pca$sdev^2) * 100 )
v
```

```{r}
## or the second row here...
z <- summary(pca)
z$importance
```

```{r}
barplot(v, xlab="Principal Component", ylab="Percent Variation")
```

```{r}
## Lets focus on PC1 as it accounts for > 90% of variance 
par(mar=c(10, 3, 0.35, 0))
barplot( pca$rotation[,1], las=2, col=rainbow(14) )
```

>Q9: Generate a similar ‘loadings plot’ for PC2. What two food groups feature prominantely and what does PC2 maninly tell us about?

```{r}
## Lets focus on PC1 as it accounts for > 90% of variance 
par(mar=c(10, 3, 0.35, 0))
barplot( pca$rotation[,2], las=2, col=rainbow(14))
```


